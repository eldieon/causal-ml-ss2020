from causalml.dataset import *
from causalml.inference.meta import BaseRRegressor
from causalml.inference.meta import BaseTRegressor
from causalml.metrics.visualize import *
from sklearn.linear_model import LinearRegression
from sklearn.neural_network import MLPRegressor
from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor
import stacking_helpers
import statsmodels.api as sm
import copy
import matplotlib.pyplot as plt
import pandas as pd
import simple_model

estimators_R = {'learner_xgb': BaseRRegressor(learner=XGBRegressor()),
                'learner_lr': BaseRRegressor(learner=LinearRegression()),
                'learner_dtr': BaseRRegressor(learner=DecisionTreeRegressor())}

predictions_easy_treatment_R = get_synthetic_preds(simulate_nuisance_and_easy_treatment,
                                                 n=1000,
                                                 estimators=estimators_R)
predictions_easy_treatment_test_R = get_synthetic_preds(simulate_nuisance_and_easy_treatment,
                                                      n=1000,
                                                      estimators=estimators_R)

predictions_randomized_trial_R = get_synthetic_preds(simulate_randomized_trial,
                                                   n=1000,
                                                   estimators=estimators_R)
predictions_randomized_trial_test_R = get_synthetic_preds(simulate_randomized_trial,
                                                        n=1000,
                                                        estimators=estimators_R)

predictions_easy_propensity_R = get_synthetic_preds(simulate_easy_propensity_difficult_baseline,
                                                  n=1000,
                                                  estimators=estimators_R)
predictions_easy_propensity_test_R = get_synthetic_preds(simulate_easy_propensity_difficult_baseline,
                                                       n=1000,
                                                       estimators=estimators_R)


def fit_and_eval_learners(predictions, predictions_test, data_generating_func):
    """
    :param predictions: data dictionary of predictions generated by causalml library
    :param predictions_test: data dictionary of predictions generated by causalml library, same models, used for testing the stacking function
    :param data_generating_func: name of the type of dataset
    :return:
    """
    predictions_copy = copy.deepcopy(predictions)
    [predictions_copy.pop(key) for key in ['Actuals', 'generated_data']]

    # compare single R learners on their own
    simple_model.multilayer_hist(predictions_copy, predictions['Actuals'], 121)
    plt.title('Distribution of CATE Predictions by input algorithms to the R learner' + data_generating_func)
    plt.xlabel('Individual Treatment Effect (ITE/CATE)')
    plt.ylabel('number of observations')
    _ = plt.legend()

    # fit an ensemble using the predictions of the R learner
    ens_model = stacking_helpers.do_stacking(predictions, predictions['Actuals'])

    predictions_test_copy = copy.deepcopy(predictions_test)
    [predictions_test_copy.pop(key) for key in ['Actuals', 'generated_data']]

    testdf = pd.DataFrame(predictions_test_copy, index=[np.arange(0, 1000), ])
    ens_params = ens_model.params

    final_predictions = np.dot(testdf, ens_model.params)

    simple_model.multilayer_hist({'ensemble_R_learner': final_predictions}, predictions_test['Actuals'], 122)
    plt.title('distribution of stacked estimates of treatment effect :' + data_generating_func)
    plt.xlabel('Individual Treatment Effect (ITE/CATE)')
    plt.ylabel('number of observations')
